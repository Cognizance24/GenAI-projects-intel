{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a1ef2a0-27b1-4557-8fea-e737eaa7f404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/u46b3a2be5da98bf6a6c85a8a5f5ea12/.local/lib/python3.9/site-packages (1.14.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/u46b3a2be5da98bf6a6c85a8a5f5ea12/.local/lib/python3.9/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/u46b3a2be5da98bf6a6c85a8a5f5ea12/.local/lib/python3.9/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/u46b3a2be5da98bf6a6c85a8a5f5ea12/.local/lib/python3.9/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/u46b3a2be5da98bf6a6c85a8a5f5ea12/.local/lib/python3.9/site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in /home/u46b3a2be5da98bf6a6c85a8a5f5ea12/.local/lib/python3.9/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/intel/oneapi/intelpython/envs/pytorch-gpu/lib/python3.9/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/intel/oneapi/intelpython/envs/pytorch-gpu/lib/python3.9/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/intel/oneapi/intelpython/envs/pytorch-gpu/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/u46b3a2be5da98bf6a6c85a8a5f5ea12/.local/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/intel/oneapi/intelpython/envs/pytorch-gpu/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/u46b3a2be5da98bf6a6c85a8a5f5ea12/.local/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/u46b3a2be5da98bf6a6c85a8a5f5ea12/.local/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/u46b3a2be5da98bf6a6c85a8a5f5ea12/.local/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/u46b3a2be5da98bf6a6c85a8a5f5ea12/.local/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install openai --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc0cfffb-3f98-45b7-9544-8b5464d19405",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import intel_extension_for_pytorch as ipex  # Used for optimizing PyTorch models\n",
    "from PIL import Image\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Image as IPImage\n",
    "\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "import openai as OpenAI\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "OpenAI.api_key = \"\"\n",
    "model_dir = \"/home/common/data/Big_Data/GenAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd31ef34-6f84-4381-abc4-01b9cd692dd9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Text2ImgModel:\n",
    "    \"\"\"\n",
    "    Text2ImgModel is a class for generating images based on text prompts using a pretrained model.\n",
    "\n",
    "    Attributes:\n",
    "    - device: The device to run the model on. Default to \"xpu\" - Intel dGPUs.\n",
    "    - pipeline: The loaded model pipeline.\n",
    "    - data_type: The data type to use in the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_id_or_path: str,\n",
    "        device: str = \"xpu\",\n",
    "        torch_dtype: torch.dtype = torch.bfloat16,\n",
    "        optimize: bool = True,\n",
    "        enable_scheduler: bool = False,\n",
    "        warmup: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        The initializer for Text2ImgModel class.\n",
    "\n",
    "        Parameters:\n",
    "        - model_id_or_path: The identifier or path of the pretrained model.\n",
    "        - device: The device to run the model on. Default is \"xpu\".\n",
    "        - torch_dtype: The data type to use in the model. Default is torch.bfloat16.\n",
    "        - optimize: Whether to optimize the model after loading. Default is True.\n",
    "        \"\"\"\n",
    "\n",
    "        self.device = device\n",
    "        self.pipeline = self._load_pipeline(model_id_or_path, torch_dtype, enable_scheduler)\n",
    "        self.data_type = torch_dtype\n",
    "        if optimize:\n",
    "            start_time = time.time()\n",
    "            self.optimize_pipeline()\n",
    "        if warmup:\n",
    "            self.warmup_model()\n",
    "\n",
    "    def _load_pipeline(\n",
    "        self,\n",
    "        model_id_or_path: str,\n",
    "        torch_dtype: torch.dtype,\n",
    "        enable_scheduler: bool,\n",
    "\n",
    "    ) -> DiffusionPipeline:\n",
    "        \"\"\"\n",
    "        Loads the pretrained model and prepares it for inference.\n",
    "\n",
    "        Parameters:\n",
    "        - model_id_or_path: The identifier or path of the pretrained model.\n",
    "        - torch_dtype: The data type to use in the model.\n",
    "\n",
    "        Returns:\n",
    "        - pipeline: The loaded model pipeline.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Creating a new story...\")\n",
    "        model_path = Path(f\"{model_dir}/{model_id_or_path}\")  \n",
    "        \n",
    "        if model_path.exists():\n",
    "            load_path = model_path\n",
    "        else:\n",
    "            load_path = model_id_or_path\n",
    "\n",
    "        pipeline = DiffusionPipeline.from_pretrained(\n",
    "            load_path,\n",
    "            torch_dtype=torch_dtype,\n",
    "            use_safetensors=True,\n",
    "            variant=\"fp16\",\n",
    "        )\n",
    "        if enable_scheduler:\n",
    "            pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "                pipeline.scheduler.config\n",
    "            )\n",
    "        if not model_path.exists():\n",
    "            try:\n",
    "                print(f\"Attempting to save the model to {model_path}...\")\n",
    "                pipeline.save_pretrained(f\"{model_path}\")\n",
    "                print(\"Model saved.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while saving the model: {e}. Proceeding without saving.\")\n",
    "        pipeline = pipeline.to(self.device)\n",
    "        return pipeline\n",
    "\n",
    "    def _optimize_pipeline(self, pipeline: DiffusionPipeline) -> DiffusionPipeline:\n",
    "        \"\"\"\n",
    "        Optimizes the model for inference using ipex.\n",
    "\n",
    "        Parameters:\n",
    "        - pipeline: The model pipeline to be optimized.\n",
    "\n",
    "        Returns:\n",
    "        - pipeline: The optimized model pipeline.\n",
    "        \"\"\"\n",
    "\n",
    "        for attr in dir(pipeline):\n",
    "            try:\n",
    "                if isinstance(getattr(pipeline, attr), nn.Module):\n",
    "                    setattr(\n",
    "                        pipeline,\n",
    "                        attr,\n",
    "                        ipex.optimize(\n",
    "                            getattr(pipeline, attr).eval(),\n",
    "                            dtype=pipeline.text_encoder.dtype,\n",
    "                            inplace=True,\n",
    "                        ),\n",
    "                    )\n",
    "            except AttributeError:\n",
    "                pass\n",
    "        return pipeline\n",
    "\n",
    "    def warmup_model(self):\n",
    "        \"\"\"\n",
    "        Warms up the model by generating a sample image.\n",
    "        \"\"\"\n",
    "        print(\"Setting up model...\")\n",
    "        start_time = time.time()\n",
    "        self.generate_images(\n",
    "            prompt=\"A beautiful sunset over the mountains\",\n",
    "            num_images=1,\n",
    "            save_path=\".tmp\",\n",
    "        )\n",
    "        print(\n",
    "            \"Model is set up and ready! Warm-up completed in {:.2f} seconds.\".format(\n",
    "                time.time() - start_time\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def optimize_pipeline(self) -> None:\n",
    "        \"\"\"\n",
    "        Optimizes the current model pipeline.\n",
    "        \"\"\"\n",
    "\n",
    "        self.pipeline = self._optimize_pipeline(self.pipeline)\n",
    "\n",
    "    def generate_images(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        num_inference_steps: int = 200,\n",
    "    ) -> Image.Image:\n",
    "        \n",
    "        with torch.xpu.amp.autocast(enabled = True if self.data_type != torch.float32 else False,dtype=self.data_type,):\n",
    "            image = self.pipeline(prompt = prompt, num_inference_steps = num_inference_steps,).images[0]\n",
    "            \n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac577cc-f98f-4701-808a-9153eccebbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, text, model = \"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = \"\"\n",
    "    try:\n",
    "        response = OpenAI.chat.completions.create(model = model, messages = messages, temperature = 0,)\n",
    "    except:\n",
    "        print(\"\\n\\nOpenAI LLM is not responding. Proper story can't be generated...\")\n",
    "        return text\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def get_prompt(input):\n",
    "    message = f\"\"\"\n",
    "    A part of a story will be provided to you and you have to generate a simple prompt that describes the \\\n",
    "    scenario in that part of the story such that the part of the story can be explained in an image generated by the prompt generated by you.\n",
    "    \n",
    "    Here are some rules u have to follow while generating the prompts: \n",
    "    1. The prompt be strictly less than 70 words.\n",
    "    2. Don't include special characters other than comma and hyphen and dot.\n",
    "    3. You just have to describe the scenario not write the whole story.\n",
    "    4. Always include \"A colored cartoon type sketch of,\" at the start of every prompt.\n",
    "    5. The very important one, write in crisp and very simple english, don't use complicated words.\n",
    "    6. Separate the different traits of the scenario with commas.\n",
    "    7. If you can't understand the story or text, just write whatever you think the situation could be in the text.\n",
    "    \n",
    "    Here are some examples on how to generate the prompt:\n",
    "    \n",
    "    Example story paragraph:\n",
    "    Once upon a time, in a not-so-distant future, there lived a man named Alex. Alex was an adventurous soul who dreamed of exploring the great \\\n",
    "    unknown: outer space. From a young age, he would gaze up at the stars with wonder, imagining what it would be like to journey among them.\n",
    "    Expected text from you is:\n",
    "    A colored cartoon type sketch of, a man looking up in the sky at night, sky has stars & moon.\n",
    "    \n",
    "    Example story paragraph:\n",
    "    As the days turned into weeks, Maya forged friendships with the creatures of the jungle. She shared moments of laughter with mischievous monkeys, \\\n",
    "    and learned the ancient wisdom of wise old elephants. Together, they explored hidden caves and winding rivers, each new discovery fueling Maya's sense of wonder.\n",
    "    Expected text from you is:\n",
    "    A colored cartoon type sketch of, A girl laughing with monkeys, old elephants, hidden caves, winding rivers.\n",
    "    \n",
    "    Example story paragraph:\n",
    "    In the heart of a bustling metropolis, where skyscrapers kissed the sky and streets hummed with the \\\n",
    "    rhythm of life, there existed a city like no other. Its streets were a labyrinth of winding alleys and bustling boulevards, \\\n",
    "    lined with towering buildings that reached for the clouds.\n",
    "    Expected prompt generated from you is:\n",
    "    A colored cartoon type sketch of, a metropolitan city, high skycrapers, streets, sky with clouds.\n",
    "    \n",
    "    Example story paragraph:\n",
    "    what's up\n",
    "    Since the paragraph is vague to understand, you can assume that a person is saying what's up to another person, for this the expected \\\n",
    "    text generated by you is:\n",
    "    A colored cartoon type sketch of, two person speaking.\n",
    "    \n",
    "    Further rules:\n",
    "    Please don't generate more than 70 words, this is a must.\n",
    "    Please note that all the above examples the generated prompts were less than 20 words, you must also generate the prompts strictly less than 70 words.\n",
    "    \n",
    "    I just want the prompt from you not the explanation of why you generated that prompt.\n",
    "    Now the actual story paragraph for which the prompt is to be generated is the text delimited by triple backticks\n",
    "    Text:\n",
    "    ```{input}```\n",
    "    \"\"\"\n",
    "    return get_completion(message, input)\n",
    "\n",
    "def get_story_from_plot(plot):\n",
    "    message = f\"\"\"\n",
    "    Write a creative story for a class of small childrens based on the plot provided in text delimited by triple backticks in \\\n",
    "    3000 words.\n",
    "    Text:\n",
    "    ```{plot}```\n",
    "    \"\"\"\n",
    "    return get_completion(message, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aeba9d2-903d-4643-90fa-131f26643217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_plot(text, image):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a2da11-cb7e-4f40-8f2a-bdf905452243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_paragraphs(story_text, max_words_per_paragraph=150):\n",
    "    if story_text is None:\n",
    "        story_text = \"a man\"\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', story_text.strip())\n",
    "\n",
    "  \n",
    "    current_paragraph = ''\n",
    "    paragraphs = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        current_paragraph += sentence.strip() + ' '\n",
    "\n",
    "        if len(current_paragraph.split()) > max_words_per_paragraph:\n",
    "            sentences_in_paragraph = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', current_paragraph.strip())\n",
    "            current_paragraph = ' '.join(sentences_in_paragraph[:-1]).strip()\n",
    "\n",
    "            paragraphs.append(current_paragraph)\n",
    "\n",
    "            current_paragraph = sentence.strip() + ' '\n",
    "\n",
    "    if current_paragraph:\n",
    "        paragraphs.append(current_paragraph)\n",
    "\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "318e0aa1-0ff7-483e-a0d4-f04b8af323df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cache = {}\n",
    "\n",
    "def generate_story():\n",
    "    out = widgets.Output()\n",
    "    model_ids = [\n",
    "        \"stabilityai/stable-diffusion-2-1\",\n",
    "        \"CompVis/stable-diffusion-v1-4\",\n",
    "    ]\n",
    "    model_dropdown = widgets.Dropdown(options = model_ids, value = model_ids[0], description = \"Select Model:\",) \n",
    "    prompt_text = widgets.Text(value=\"\", placeholder = \"Enter the plot\", description = \"Story plot:\", layout = widgets.Layout(width = \"600px\"))\n",
    "        \n",
    "    layout = widgets.Layout(margin = \"10px\")\n",
    "    button1 = widgets.Button(description = \"Generate Story\", button_style = \"primary\")\n",
    "    button2 = widgets.Button(description = \"Clear Story\", button_style = \"primary\")\n",
    "    model_dropdown.layout.width = \"50%\"\n",
    "    prompt_text.layout.width = \"600px\"\n",
    "    button1.layout.margin = \"0 0 0 100px\"\n",
    "    button1.layout.width = \"150px\"\n",
    "    button2.layout.margin = \"0 0 0 300px\"\n",
    "    button2.layout.width = \"120px\"\n",
    "    top_row = widgets.HBox([model_dropdown])\n",
    "    bottom_row = widgets.HBox([prompt_text])\n",
    "    top_box = widgets.VBox([top_row, bottom_row])\n",
    "    user_input_widgets = widgets.HBox([top_box], layout = layout)\n",
    "    bottom_box = widgets.HBox([button1, button2], layout = layout)\n",
    "    display(user_input_widgets)\n",
    "    display(bottom_box)\n",
    "    display(out)\n",
    "\n",
    "    \n",
    "    def generate_image(button):\n",
    "        clear_output(wait = True)\n",
    "        print(\"Creating a new story...\")\n",
    "        story = get_story_from_plot(prompt_text.value)\n",
    "        print(f\"Story : {story}\")\n",
    "        partial_stories = split_paragraphs(story)\n",
    "        for i, parts in enumerate(partial_stories):\n",
    "            print(f\"Part {i} : {parts}\")\n",
    "            with out:\n",
    "                button.button_style = \"warning\"\n",
    "                selected_model_index = model_ids.index(model_dropdown.value)\n",
    "                model_id = model_ids[selected_model_index]\n",
    "                model_key = (model_id, \"xpu\")\n",
    "                if model_key not in model_cache:\n",
    "                    model_cache[model_key] = Text2ImgModel(model_id, device = \"xpu\")\n",
    "                model = model_cache[model_key]\n",
    "                prompt = get_prompt(parts)\n",
    "                if not prompt:\n",
    "                    prompt = \" \"  \n",
    "                try:\n",
    "                    start_time = time.time()\n",
    "                    \n",
    "                    image = model.generate_images(\n",
    "                        prompt,\n",
    "                        num_inference_steps = 200,\n",
    "                    )\n",
    "                    display_plot(parts, image)\n",
    "                except KeyboardInterrupt:\n",
    "                    print(\"\\nUser interrupted image generation...\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "                finally:\n",
    "                    button.button_style = \"primary\"\n",
    "\n",
    "    def end_story(button):\n",
    "        with out:\n",
    "            clear_output(wait = True)\n",
    "            print(\"Creating a new story...\")\n",
    "            \n",
    "    button1.on_click(generate_image)\n",
    "    button2.on_click(end_story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c73cfed7-f8f2-4f9b-be8e-e9c2b3d545a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166085503dc34271a28b0330b3fe7280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HBox(children=(Dropdown(description='Select Model:', layout=Layout(width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b6b20d4cd4404b900c4502eac7cc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='primary', description='Generate Story', layout=Layout(margin='0 0 0 100px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca8eaa373814bcd82b75ca2b128c43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_story()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46798f-54f3-4104-bf81-99b2a001e766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474e65e-5278-4818-a8e1-56d062166c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
