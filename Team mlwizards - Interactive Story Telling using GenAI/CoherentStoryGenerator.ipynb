{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bab46b17-057c-4981-88d7-ee5373b20bca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "SPDX-License-Identifier: Apache-2.0\n",
    "Copyright (c) 2023, Rahul Unnikrishnan Nair <rahul.unnikrishnan.nair@intel.com>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c4ee2d-e6ca-4c63-b65c-340015386d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation in progress...\n",
      "Installtion complete...\n"
     ]
    }
   ],
   "source": [
    "# Required packages, install if not installed (assume PyTorch* and Intel® Extension for PyTorch* is already present)\n",
    "!echo \"Installation in progress...\"\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install  invisible-watermark > /dev/null\n",
    "# !conda install -y --quiet --prefix {sys.prefix}  -c conda-forge \\\n",
    "#     accelerate==0.23.0 \\\n",
    "#     validators==0.22.0 \\\n",
    "#     diffusers==0.18.2 \\\n",
    "#     transformers==4.32.1 \\\n",
    "#     tensorboardX \\\n",
    "#     pillow \\\n",
    "#     ipywidgets \\\n",
    "#     ipython > /dev/null && echo \"Installation successful\" || echo \"Installation failed\"\n",
    "import sys\n",
    "!{sys.executable} -m pip install invisible-watermark --user > /dev/null 2>&1\n",
    "!{sys.executable} -m pip install openai --user > /dev/null 2>&1\n",
    "#!{sys.executable} -m pip install transformers huggingface-hub --user > /dev/null 2>&1\n",
    "!echo \"Installtion complete...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe0f41a-baea-4cdf-ac53-be8700eea3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import intel_extension_for_pytorch as ipex  # Used for optimizing PyTorch models\n",
    "from PIL import Image\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Image as IPImage\n",
    "\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "import openai as OpenAI\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler, StableDiffusionImg2ImgPipeline\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "OpenAI.api_key = \"\"\n",
    "model_dir = \"/home/common/data/Big_Data/GenAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f109873-2cf1-4dea-9b7a-77fa4191b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, text, model = \"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = \"\"\n",
    "    try:\n",
    "        response = OpenAI.chat.completions.create(model = model, messages = messages, temperature = 0,)\n",
    "    except:\n",
    "        print(\"\\n\\nOpenAI LLM is not responding. Proper story can't be generated...\")\n",
    "        return text\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def get_prompt(input):\n",
    "    message = f\"\"\"\n",
    "    A part of a story will be provided to you and you have to generate a simple prompt that describes the \\\n",
    "    scenario in that part of the story such that the part of the story can be explained in an image generated by the prompt generated by you.\n",
    "    \n",
    "    Here are some rules u have to follow while generating the prompts: \n",
    "    1. The prompt be strictly less than 70 words.\n",
    "    2. Don't include special characters other than comma and hyphen and dot.\n",
    "    3. You just have to describe the scenario not write the whole story.\n",
    "    4. Always include \"A colored cartoon type sketch of,\" at the start of every prompt.\n",
    "    5. The very important one, write in crisp and very simple english, don't use complicated words.\n",
    "    6. Separate the different traits of the scenario with commas.\n",
    "    7. If you can't understand the story or text, just write whatever you think the situation could be in the text.\n",
    "    \n",
    "    Here are some examples on how to generate the prompt:\n",
    "    \n",
    "    Example story paragraph:\n",
    "    Once upon a time, in a not-so-distant future, there lived a man named Alex. Alex was an adventurous soul who dreamed of exploring the great \\\n",
    "    unknown: outer space. From a young age, he would gaze up at the stars with wonder, imagining what it would be like to journey among them.\n",
    "    Expected text from you is:\n",
    "    A colored cartoon type sketch of, a man looking up in the sky at night, sky has stars & moon.\n",
    "    \n",
    "    Example story paragraph:\n",
    "    As the days turned into weeks, Maya forged friendships with the creatures of the jungle. She shared moments of laughter with mischievous monkeys, \\\n",
    "    and learned the ancient wisdom of wise old elephants. Together, they explored hidden caves and winding rivers, each new discovery fueling Maya's sense of wonder.\n",
    "    Expected text from you is:\n",
    "    A colored cartoon type sketch of, A girl laughing with monkeys, old elephants, hidden caves, winding rivers.\n",
    "    \n",
    "    Example story paragraph:\n",
    "    In the heart of a bustling metropolis, where skyscrapers kissed the sky and streets hummed with the \\\n",
    "    rhythm of life, there existed a city like no other. Its streets were a labyrinth of winding alleys and bustling boulevards, \\\n",
    "    lined with towering buildings that reached for the clouds.\n",
    "    Expected prompt generated from you is:\n",
    "    A colored cartoon type sketch of, a metropolitan city, high skycrapers, streets, sky with clouds.\n",
    "    \n",
    "    Example story paragraph:\n",
    "    what's up\n",
    "    Since the paragraph is vague to understand, you can assume that a person is saying what's up to another person, for this the expected \\\n",
    "    text generated by you is:\n",
    "    A colored cartoon type sketch of, two person speaking.\n",
    "    \n",
    "    Further rules:\n",
    "    Please don't generate more than 70 words, this is a must.\n",
    "    Please note that all the above examples the generated prompts were less than 20 words, you must also generate the prompts strictly less than 70 words.\n",
    "    \n",
    "    I just want the prompt from you not the explanation of why you generated that prompt.\n",
    "    Now the actual story paragraph for which the prompt is to be generated is the text delimited by triple backticks\n",
    "    Text:\n",
    "    ```{input}```\n",
    "    \"\"\"\n",
    "    return get_completion(message, input)\n",
    "\n",
    "def get_story_from_plot(plot):\n",
    "    message = f\"\"\"\n",
    "    Write a creative story based on the plot provided in text delimited by triple backticks in \\\n",
    "    3000 words.\n",
    "    Text:\n",
    "    ```{plot}```\n",
    "    \"\"\"\n",
    "    return get_completion(message, plot)\n",
    "\n",
    "def get_bgnumber(para):\n",
    "    message = f\"\"\"\n",
    "    You will be given a part of a story you have to read that part and have to infere the probable and most suitable location/surrounding in which it's taking place. \n",
    "    \n",
    "    You can give the output out of only the below options provided. You have to give the corresponding integer value from 1 to 15 depending on the location/surrounding you have infered:\n",
    "    City_night  ---->  1  \n",
    "    City_day  ---->    2 \n",
    "    Forest_night  ----> 3\n",
    "    Forest_day  ---->  4\n",
    "    Sea_night  ----> 5\n",
    "    Sea_day  ----> 6\n",
    "    Room_night  ----> 7\n",
    "    Room_day  ---->  8\n",
    "    Village_night  ----> 9\n",
    "    Village_day  ----> 10\n",
    "    Moutain_night  ----> 11\n",
    "    Moutain_day  ----> 12\n",
    "    Sky_Space_Universe  ----> 13\n",
    "\n",
    "    You have to strictly follow the given rules:\n",
    "    1. Always give the output as an integer between 1 to 13 no extra string or anything just an integer number between 1 to 15.\n",
    "    2. If you are able to infere the location but not able to infere whether it's day or night by default choose the option with day which is an even number \\\n",
    "    for eg. 2, 4, 6, 8, 10, and 12 all these options have day in it so choose out of these options based on the location you have infered.\n",
    "    3. If the location/surrounding isn't obvious from the text provided then by default give output as 2.\n",
    "\n",
    "    Here are some examples on how to generate the required option:\n",
    "    \n",
    "    Example story paragraph:\n",
    "    In the heart of a bustling metropolis, where skyscrapers kissed the sky and streets hummed with the \\\n",
    "    rhythm of life, there existed a city like no other. Its streets were a labyrinth of winding alleys and bustling boulevards, \\\n",
    "    lined with towering buildings that reached for the clouds.\n",
    "    \n",
    "    As from the above paragraph we can infer that the surrounding is of city and since the time of the day isn't obvious whether \\\n",
    "    it's day or night so you have to select day by default so the final surrounding infered is \"City_day\" so expected output generated from you is:\n",
    "    2\n",
    "\n",
    "    Example story paragraph:\n",
    "    As the days turned into weeks, Maya forged friendships with the creatures of the jungle. She shared moments of laughter with mischievous monkeys, \\\n",
    "    and learned the ancient wisdom of wise old elephants. Together, they explored hidden caves and winding rivers, each new discovery fueling Maya's sense of wonder.\n",
    "    \n",
    "    As from the above paragraph we can infer that the surrounding is of forest/jungle and since the time of the day isn't obvious whether \\\n",
    "    it's day or night so you have to select day by default so the final surrounding infered is \"Forest_day\" so expected output generated from you is:\n",
    "    4\n",
    "\n",
    "    Example story paragraph:\n",
    "    Once upon a time, in a not-so-distant future, there lived a man named Alex. Alex was an adventurous soul who dreamed of exploring the great \\\n",
    "    unknown: outer space. From a young age, he would gaze up at the stars with wonder, imagining what it would be like to journey among them.\n",
    "\n",
    "    As from the above paragraph we can infer that the surrounding is of Space/Sky/Universe so the expected output from you is:\n",
    "    13\n",
    "\n",
    "    Example story paragraph:\n",
    "    Under the shimmering canopy of a star-studded night sky, a young boy named Ethan ventures to the edge of the sea. The moon casts a soft, silvery \\\n",
    "    glow upon the restless waves, inviting him into their mysterious depths. With bare feet sinking into cool, wet sand, Ethan hesitates for a moment \\\n",
    "    before plunging into the salty embrace of the ocean. The water is surprisingly warm, and he feels a surge of exhilaration as he dives beneath the \\\n",
    "    surface. Bioluminescent creatures sparkle like underwater stars, illuminating his path as he swims further out. With each stroke, he feels a \\\n",
    "    sense of freedom and wonder, lost in the magic of the nocturnal sea. Laughter echoes in the darkness as Ethan dances with the waves, \\\n",
    "    creating memories that will linger long after the night fades into dawn.\n",
    "\n",
    "    As from the above paragraph we can infer that the surrounding is of Sea/ocean and the time is of night so the expected output from you is of Sea_night:\n",
    "    5\n",
    "\n",
    "    \n",
    "    Example story paragraph:\n",
    "    what's up\n",
    "    Since the location/surrounding to infere is difficult for the above text, you can assume that a person is saying what's up to another person, for this the expected \\\n",
    "    number generated by you is:\n",
    "    2\n",
    "\n",
    "    Now the actual story paragraph for which the number is to be generated is the text delimited by triple backticks\n",
    "    Text:\n",
    "    ```{para}```\n",
    "    \"\"\"\n",
    "    return get_completion(message, \"10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31324959-3ade-40d7-bbf5-feb885d931f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Img2ImgModel:\n",
    "    \"\"\"\n",
    "    This class creates a model for transforming images based on given prompts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_id_or_path: str,\n",
    "        device: str = \"xpu\",\n",
    "        torch_dtype: torch.dtype = torch.bfloat16,\n",
    "        optimize: bool = True,\n",
    "        warmup: bool = False,\n",
    "        scheduler: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the model with the specified parameters.\n",
    "\n",
    "        Args:\n",
    "            model_id_or_path (str): The ID or path of the pre-trained model.\n",
    "            device (str, optional): The device to run the model on. Defaults to \"xpu\".\n",
    "            torch_dtype (torch.dtype, optional): The data type to use for the model. Defaults to torch.float16.\n",
    "            optimize (bool, optional): Whether to optimize the model. Defaults to True.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.data_type = torch_dtype\n",
    "        self.scheduler = scheduler\n",
    "        self.generator = torch.Generator()  # .manual_seed(99)\n",
    "        self.pipeline = self._load_pipeline(model_id_or_path, torch_dtype)\n",
    "        if optimize:\n",
    "            start_time = time.time()\n",
    "            #print(\"Optimizing the model...\")\n",
    "            self.optimize_pipeline()\n",
    "            #print(\n",
    "            #    \"Optimization completed in {:.2f} seconds.\".format(\n",
    "            #        time.time() - start_time\n",
    "            #    )\n",
    "            #)\n",
    "        if warmup:\n",
    "            self.warmup_model()\n",
    "\n",
    "    def _load_pipeline(\n",
    "        self, model_id_or_path: str, torch_dtype: torch.dtype\n",
    "    ) -> StableDiffusionImg2ImgPipeline:\n",
    "        \"\"\"\n",
    "        Load the pipeline for the model.\n",
    "\n",
    "        Args:\n",
    "            model_id_or_path (str): The ID or path of the pre-trained model.\n",
    "            torch_dtype (torch.dtype): The data type to use for the model.\n",
    "\n",
    "        Returns:\n",
    "            StableDiffusionImg2ImgPipeline: The loaded pipeline.\n",
    "        \"\"\"\n",
    "        print(\"Loading the model...\")\n",
    "        model_path = Path(f\"{model_dir}/{model_id_or_path}\")\n",
    "        \n",
    "        if model_path.exists():\n",
    "            #print(f\"Loading the model from {model_path}...\")\n",
    "            load_path = model_path\n",
    "        else:\n",
    "            print(\"Using the default path for models...\")\n",
    "            load_path = model_id_or_path\n",
    "            \n",
    "        pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "            load_path,\n",
    "            torch_dtype = torch_dtype,\n",
    "            use_safetensors = True,\n",
    "            variant = \"fp16\",\n",
    "        )\n",
    "        if self.scheduler:\n",
    "            pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "                pipeline.scheduler.config\n",
    "            )\n",
    "        if not model_path.exists():\n",
    "            try:\n",
    "                print(f\"Attempting to save the model to {model_path}...\")\n",
    "                pipeline.save_pretrained(f\"{model_path}\")\n",
    "                print(\"Model saved.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while saving the model: {e}. Proceeding without saving.\")\n",
    "        pipeline = pipeline.to(self.device)\n",
    "        #print(\"Model loaded.\")\n",
    "        return pipeline\n",
    "\n",
    "    \n",
    "    def _optimize_pipeline(self, pipeline: StableDiffusionImg2ImgPipeline) -> StableDiffusionImg2ImgPipeline:\n",
    "        \"\"\"\n",
    "        Optimize the pipeline of the model.\n",
    "\n",
    "        Args:\n",
    "            pipeline (StableDiffusionImg2ImgPipeline): The pipeline to optimize.\n",
    "\n",
    "        Returns:\n",
    "            StableDiffusionImg2ImgPipeline: The optimized pipeline.\n",
    "        \"\"\"\n",
    "\n",
    "        for attr in dir(pipeline):\n",
    "            try:\n",
    "                if isinstance(getattr(pipeline, attr), nn.Module):\n",
    "                    setattr(\n",
    "                        pipeline,\n",
    "                        attr,\n",
    "                        ipex.optimize(\n",
    "                            getattr(pipeline, attr).eval(),\n",
    "                            dtype=pipeline.text_encoder.dtype,\n",
    "                            inplace=True,\n",
    "                        ),\n",
    "                    )\n",
    "            except AttributeError:\n",
    "                pass\n",
    "        return pipeline\n",
    "\n",
    "    def optimize_pipeline(self) -> None:\n",
    "        \"\"\"\n",
    "        Optimize the pipeline of the model.\n",
    "        \"\"\"\n",
    "        self.pipeline = self._optimize_pipeline(self.pipeline)\n",
    "\n",
    "    def get_image(self, prompt) -> Image.Image:\n",
    "        image_number = 10\n",
    "        try:\n",
    "            image_number = int(get_bgnumber(prompt))\n",
    "        except:\n",
    "            image_number = 10\n",
    "        if image_number < 1 or image_number > 13:\n",
    "            image_number = 10\n",
    "        img = Image.open(f'./base/{image_number}'+'.jpg')\n",
    "        img = img.resize((512, 300))\n",
    "        return img\n",
    "\n",
    "    def generate_images(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        num_inference_steps: int = 200,\n",
    "        strength: float = 0.75,\n",
    "        guidance_scale: float = 7.5,\n",
    "        batch_size: int = 1,\n",
    "    ):\n",
    "        time.sleep(22)\n",
    "        init_image = self.get_image(prompt)\n",
    "        time.sleep(22)\n",
    "        try:\n",
    "            prompt = get_prompt(prompt)\n",
    "        except:\n",
    "            prompt = prompt\n",
    "        image = self.pipeline(\n",
    "            prompt = prompt,\n",
    "            image = init_image,\n",
    "            strength = strength,\n",
    "            guidance_scale = guidance_scale,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "        ).images\n",
    "\n",
    "        return image[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "babf2dd2-f0f2-41c0-ac63-0991f035141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_plot(text, image):\n",
    "    print(\"okay1\")\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    Image.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(\"okay2\")\n",
    "    print(text)\n",
    "    print(\"okay3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4fe151b-7da0-462a-bff7-a0d978186c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_paragraphs(story_text, max_words_per_paragraph = 150):\n",
    "    if story_text is None:\n",
    "        story_text = \"a man\"\n",
    "        \n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', story_text.strip())\n",
    "\n",
    "    current_paragraph = ''\n",
    "    paragraphs = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        current_paragraph += sentence.strip() + ' '\n",
    "\n",
    "        if len(current_paragraph.split()) > max_words_per_paragraph:\n",
    "            sentences_in_paragraph = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', current_paragraph.strip())\n",
    "\n",
    "            current_paragraph = ' '.join(sentences_in_paragraph[:-1]).strip()\n",
    "\n",
    "            paragraphs.append(current_paragraph)\n",
    "\n",
    "            current_paragraph = sentence.strip() + ' '\n",
    "\n",
    "    if current_paragraph:\n",
    "        paragraphs.append(current_paragraph)\n",
    "\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e03357-64e9-42af-a1f7-923b57785a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1143746-27c5-4c2d-ac1f-5b4ac3df529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cache = {}\n",
    "\n",
    "def generate_story():\n",
    "    out = widgets.Output()\n",
    "    model_ids = [\n",
    "        \"runwayml/stable-diffusion-v1-5\",\n",
    "        \"stabilityai/stable-diffusion-2-1\",\n",
    "    ]\n",
    "    model_dropdown = widgets.Dropdown(options = model_ids, value = model_ids[0], description = \"Select Model:\",) \n",
    "    prompt_text = widgets.Text(value=\"\", placeholder = \"Describe your story in short\", description = \"Enter Story:\", layout = widgets.Layout(width = \"600px\"))\n",
    "    \n",
    "    layout = widgets.Layout(margin = \"10px\")\n",
    "    button1 = widgets.Button(description = \"Generate Story\", button_style = \"primary\")\n",
    "    button2 = widgets.Button(description = \"Clear Story\", button_style = \"primary\")\n",
    "    model_dropdown.layout.width = \"50%\"\n",
    "    prompt_text.layout.width = \"600px\"\n",
    "    button1.layout.margin = \"0 0 0 100px\"\n",
    "    button1.layout.width = \"150px\"\n",
    "    button2.layout.margin = \"0 0 0 300px\"\n",
    "    button2.layout.width = \"120px\"\n",
    "    top_row = widgets.HBox([model_dropdown])\n",
    "    bottom_row = widgets.HBox([prompt_text])\n",
    "    top_box = widgets.VBox([top_row, bottom_row])\n",
    "    user_input_widgets = widgets.HBox([top_box], layout = layout)\n",
    "    bottom_box = widgets.HBox([button1, button2], layout = layout)\n",
    "    display(user_input_widgets)\n",
    "    display(bottom_box)\n",
    "    display(out)\n",
    "    \n",
    "   \n",
    "    \n",
    "    def generate_image(button):\n",
    "        clear_output(wait = True)\n",
    "        print(\"Creating a new story...\")\n",
    "        story = get_story_from_plot(prompt_text.value)\n",
    "        partial_stories = split_paragraphs(story)\n",
    "        for i, parts in enumerate(partial_stories):\n",
    "            with out:\n",
    "                button.button_style = \"warning\"\n",
    "                selected_model_index = model_ids.index(model_dropdown.value)\n",
    "                model_id = model_ids[selected_model_index]\n",
    "                model_key = (model_id, \"xpu\")\n",
    "                if model_key not in model_cache:\n",
    "                    model_cache[model_key] = Img2ImgModel(model_id, device = \"xpu\")\n",
    "                prompt = parts\n",
    "                model = model_cache[model_key]\n",
    "                if not prompt:\n",
    "                    prompt = \"a man\"  \n",
    "                try:\n",
    "                    start_time = time.time()\n",
    "                    image = model.generate_images(prompt = prompt,)\n",
    "                    image.show()\n",
    "                    print(prompt)\n",
    "                except KeyboardInterrupt:\n",
    "                    print(\"\\nUser interrupted image generation...\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "                finally:\n",
    "                    button.button_style = \"primary\"\n",
    "\n",
    "    def end_story(button):\n",
    "        with out:\n",
    "            clear_output(wait = True)\n",
    "            print(\"Creating a new story....\")\n",
    "            \n",
    "    button1.on_click(generate_image)\n",
    "    button2.on_click(end_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ae0b59-ae64-4651-a880-65fb0c9cf138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059479d2a6c84142b3d6a1aef90c9b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HBox(children=(Dropdown(description='Select Model:', layout=Layout(width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b784e5cb2d42bfb11c591d08c23306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='primary', description='Generate Story', layout=Layout(margin='0 0 0 100px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b01a66c77948d893cfac34909de56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_story()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d12151-ad51-4093-8082-3a033b4f22ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886c28f-9b3d-4cef-a68e-b0a7f20eecd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
