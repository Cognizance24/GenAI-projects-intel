{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d14ae6c",
   "metadata": {},
   "source": [
    "## Installing Intel Optimized Libraries from Intel AI Analytic Toolkit(Pytorch and Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b662dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.13.1+cpu torchvision==0.14.1+cpu â€“f https://download.pytorch.org/whl/torch_stable.html\n",
    "# !pip install intel_extension_for_pytorch==1.13.100 -f https://developer.intel.com/ipex-whl-stable-cpu\n",
    "# !pip install intel-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c1fd3",
   "metadata": {},
   "source": [
    "## Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b481f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import os\n",
    "import io\n",
    "import pyttsx3\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
    "from diffusers.utils import load_image\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from PIL import Image\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "\n",
    "if(\"result\" not in os.listdir(os.getcwd())):\n",
    "    os.makedirs(\"result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa713f0c",
   "metadata": {},
   "source": [
    "## Loading Text to Image Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a79deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "#if ipex installed run this or run the line below it\n",
    "text_to_image_pipeline = ipex.optimize(StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float32))\n",
    "# text_to_image_pipeline = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64a101c",
   "metadata": {},
   "source": [
    "## Function to generate story based on user input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbb90fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story_extension(user_input, tokenizer, model_name, temperature=0.85, max_new_tokens=1000):\n",
    " \n",
    "  generator = pipeline(\"text-generation\", model=model_name, tokenizer=tokenizer)\n",
    "  story_extension = generator(user_input, max_new_tokens=max_new_tokens, num_return_sequences=1, temperature=temperature)[0]['generated_text'][len(user_input)+1:]\n",
    "\n",
    "  return story_extension.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9117164",
   "metadata": {},
   "source": [
    "## Loading Text to Text model and Tokeniser for the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33144508",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = AutoTokenizer.from_pretrained(\"Intel/neural-chat-7b-v3-3\")\n",
    "#if ipex installed run this or run the line below it\n",
    "m1= ipex.optimize(AutoModelForCausalLM.from_pretrained(\"Intel/neural-chat-7b-v3-3\"))\n",
    "# m1= AutoModelForCausalLM.from_pretrained(\"Intel/neural-chat-7b-v3-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95abb828",
   "metadata": {},
   "source": [
    "## Defining start story function and further modification according to user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe9cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_story():\n",
    "  list_of_response = []\n",
    "  updated_story = \"\"\n",
    "  base_story = \"\"\n",
    "\n",
    "  characters = input(\"Enter the name of characters along with their descriptions \\n\")\n",
    "  plot = input(\"Describe the plot in brief \\n\")\n",
    "  theme = input(\"Provide a theme of the story along with the setting \\n\")\n",
    "\n",
    "\n",
    "\n",
    "  user_input = f\"Theme and setting: {theme} plot: {plot} characters: {characters}\"\n",
    "\n",
    "  prompt = f\"generate a complete story of at least 800 words based on input given by the user: \\n {user_input} \"\n",
    "  base_story = generate_story_extension(prompt, t1, model_name=\"Intel/neural-chat-7b-v3-3\", temperature=0.85, max_new_tokens=1000)\n",
    "  updated_story = base_story\n",
    "  narrative_finished = False\n",
    "  print(\"base story starts:\",updated_story)\n",
    "  while not narrative_finished :\n",
    "      user_changed_input = input(\"If you are satisfied with the story, please type end or type out the changes you want in the form of a simple prompt\")\n",
    "      if user_changed_input.lower()==\"end\" :\n",
    "        narrative_finished = True\n",
    "        break\n",
    "      prompt_change = f\"generate a new story from scratch of at least 800 words with referene to the previously generated story and based on changes instructed by user:- \\n {user_changed_input} \"\n",
    "      updated_story =  generate_story_extension(prompt_change, t1, model_name=\"Intel/neural-chat-7b-v3-3\", temperature=0.85, max_new_tokens=1000)\n",
    "      print(updated_story)\n",
    "  return updated_story"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f57fb",
   "metadata": {},
   "source": [
    "## Calling start story function and dividing the story into certain number of parts which will be input into the Text to Image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f11c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "story=start_story()\n",
    "prompt_for_img_gen = f\"Based on the story:{story} add \\n delimiters to separate the story into at least 10  pivotal parts(each part represent a different pivotal chapter of story) and  at max 20 parts, where each pivotal part gives an illustrative desciption of 30 to 40 words about that part such that an image can be generated from the part and can be fed into a text to image model to show progressive story, try involving new setting or new characters in each part\"\n",
    "prompt_corpus = generate_story_extension(prompt_for_img_gen, t1, model_name=\"Intel/neural-chat-7b-v3-3\", temperature=0.85, max_new_tokens=1000)\n",
    "p = \"Generate an immersive visual representation capturing a pivotal scene from the story, featuring the central character(s) in a vivid setting that encapsulates the thematic essence of the narrative.\"\n",
    "print(prompt_corpus)\n",
    "li=prompt_corpus.split(\"\\n\")\n",
    "story_sequence=[]\n",
    "for x in li:\n",
    "  if 'Part' in x:\n",
    "    story_sequence.append(x)\n",
    "\n",
    "base_images = []\n",
    "for i in range(len(story_sequence)):\n",
    "    if(i>=1):\n",
    "      image = text_to_image_pipeline(story_sequence[i-1]+story_sequence[i]).images[0]  # Get the image tensor\n",
    "    else:\n",
    "      image = text_to_image_pipeline(story_sequence[i]).images[0]  # Get the image tensor\n",
    "    base_images.append(image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee9791",
   "metadata": {},
   "source": [
    "## Saving images in the result folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de2e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder=\"./result\"\n",
    "\n",
    "for i, image in enumerate(base_images):\n",
    "\n",
    "    file_path = os.path.join(save_folder, f\"base_image_{i}.png\")\n",
    "    \n",
    "    image.save(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d0d66",
   "metadata": {},
   "source": [
    "## Displaying images and playing audio simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c79cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i,image_path in enumerate(sorted(os.listdir(save_folder))):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('rate', 180)  \n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[0].id)\n",
    "    if image_path.endswith(\".png\"):  \n",
    "        full_path = os.path.join(save_folder, image_path)\n",
    "        img = Image.open(full_path) \n",
    "        img.show()\n",
    "        text = story_sequence[i]\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c85baa",
   "metadata": {},
   "source": [
    "# Tried to implement image to image model but didnt find any improvement in results so ignored it in the final result.(code may not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e644959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def refine_image_via_api(base_image, refinement_prompt):\n",
    "#     image_to_image_pipeline = pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True)\n",
    "#     refined_image_data =image_to_image_pipeline( refinement_prompt , base_image )   # Replace with actual API request\n",
    "#     refined_image = Image.open(io.BytesIO(refined_image_data))\n",
    "#     return refined_image\n",
    "\n",
    "# refined_images = []\n",
    "# for i, base_image in enumerate(base_images):\n",
    "#     context = story_sequence[:i+1]  # Context includes previous story scenes\n",
    "#     context_prompt = \" \".join(context)\n",
    "#     refinement_prompt = f\"Refine the image to depict: {context_prompt}\"\n",
    "\n",
    "#     refined_image = refine_image_via_api(base_image, refinement_prompt)\n",
    "#     refined_images.append(refined_image)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
